# 09:35
Talking with @mattsurabian.

# 10:40
Client work.

# 12:40
Found more details on why connecting to VPN clobbers connectivity:
https://github.com/kubernetes/minikube/issues/1099#issuecomment-307154111  

# 13:30
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#example-job-with-work-queue-with-pod-per-work-item  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#starting-a-message-queue-service  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#testing-the-message-queue-service  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#filling-the-queue-with-tasks  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#create-an-image  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#defining-a-job  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#running-the-job  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#alternatives  
https://kubernetes.io/docs/tasks/job/coarse-parallel-processing-work-queue/#caveats  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#example-job-with-work-queue-with-multiple-work-items-per-pod  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#starting-redis  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#filling-the-queue-with-tasks  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#create-an-image  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#push-the-image  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#defining-a-job  
https://kubernetes.io/docs/tasks/job/fine-parallel-processing-work-queue/#running-the-job  
Nice review. Not going to run these, but they make perfect sense.

# 13:40
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#deploying-the-dashboard-ui  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#accessing-the-dashboard-ui  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#command-line-proxy  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#master-server  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#welcome-view  
Makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#deploying-containerized-applications  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#specifying-application-details  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#uploading-a-yaml-or-json-file  
Neat, but no thanks.

https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#using-dashboard  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#navigation  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#admin  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#workloads  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#services-and-discovery  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#storage  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#config  
https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#logs-viewer  
All makes sense to me.

# 13:50
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-the-cluster-api  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-for-the-first-time-with-kubectl  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#directly-accessing-the-rest-api  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#using-kubectl-proxy  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#without-kubectl-proxy-before-v13x  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#without-kubectl-proxy-post-v13x  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#programmatic-access-to-the-api  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#go-client  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#python-client  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#other-languages  
All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-the-api-from-a-pod  
Pods can connect to the apiserver using the `kubernetes` DNS name and they
can auth with creds that are automatically inserted into `/var/run/....`

Checking in Pod to see for myself:
```
/var/run/secrets/kubernetes.io/serviceaccount # ls
ca.crt     namespace  token
```

https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-services-running-on-the-cluster  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#ways-to-connect  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#discovering-builtin-services  
https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#manually-constructing-apiserver-proxy-urls  
All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#examples  

Cool, you can access your service endpoints via URL rather than DNS:
http://kubernetes_master_address/api/v1/namespaces/namespace_name/services/service_name[:port_name]/proxy  
^ might break if you can't auth with the service or the service generates
URLS that are not relative.

https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#so-many-proxies  
Makes sense to me.

# 14:00
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#define-clusters-users-and-contexts  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#create-a-second-configuration-file  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#explore-the-homekube-directory  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#append-homekubeconfig-to-your-kubeconfig-environment-variable  
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#clean-up  
All makes sense to me. Just some review about configuring kubectl.

# 14:05
https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/  
https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#creating-a-pod-to-run-a-redis-server  
https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#forward-a-local-port-to-a-port-on-the-pod  
https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#discussion  
This shows how to set up port forwarding to a Pod. Super handy.

https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/  
https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/#objectives  
https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/#creating-a-service-for-an-application-running-in-two-pods  
https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/#using-a-service-configuration-file  
This is review about hwo to make a Service. All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/  
https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/#objectives  
https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/#creating-a-service-for-an-application-running-in-two-pods  
https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/#using-a-service-configuration-file  
https://kubernetes.io/docs/tasks/access-application-cluster/service-access-application-cluster/#cleaning-up  
This is review about how to make a Service. All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#objectives  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#creating-the-backend-using-a-deployment  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#creating-the-backend-service-object  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#creating-the-frontend  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#interact-with-the-frontend-service  
https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/#send-traffic-through-the-frontend  
This is review about making Deployments and Services. All makes sense to me.

# 14:10
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/  
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#configuration-file  
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#using-kubectl  
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#finding-your-ip-address  
This is review. All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip  
https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#feature-availability  
The routing for load balancing obscures the client source ip. There are some
settings you can use in the service definition that will fix this, but only
on GCE and GKE environments.

https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#external-load-balancer-providers  
This describes, somewhat poorly, how k8s creates load balancers and manages
them external to k8s (AWS ELBs, for example)

https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#caveats-and-limitations-when-preserving-source-ips  
Some errata about how external load balancers don't provide weight options
for their target pools.

# 14:20
https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/  

Restrict Access For LoadBalancer Service
Control firewall at cloud provider level with `loadBalancerSourceRanges`

Google Compute Engine
Handles opening the firewall when using service type of LoadBalancer.

Other cloud providers
They say coming soon...

https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-all-containers-in-all-namespaces  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-containers-by-pod  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-containers-filtering-by-pod-label  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-containers-filtering-by-pod-namespace  
https://kubernetes.io/docs/tasks/access-application-cluster/list-all-running-container-images/#list-containers-using-a-go-template-instead-of-jsonpath  
Some examples of using kubectl. All makes sense to me.

https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/  
https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/#before-you-begin  
https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/#creating-a-pod-that-runs-two-containers  
https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/#discussion  
This is review. All makes sense to me.

# 14:25
https://kubernetes.io/docs/tasks/debug-application-cluster/core-metrics-pipeline/  
Kubernetes gives access to metrics, but does not store them.

The Metrics API
Available at /apis/metrics.k8s.io if the metrics server is deployed.

Metrics Server
...a cluster-wide aggregator of resource usage data.
Collects from the `summary` API exposed by kubelet on each node.

https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/  
Kubernetes ships with heapster and gives detailed resource usage information
using it.

Overview
Heapster is a cluster-wide aggregator.
It runs as a Pod.
Gets data from kubelet, which gets it's data from cAdvisor.

cAdvisor
Open source container resource usage and performance analysis agent. Built
into kubelet. Auto discovers all containers on the system and gets all the
golden signals.
Accessible on port 4194.

Testing.

...sure enough, can be hit with http://<minikube-cluster-ip>:4194/

Kubelet
Bridge between k8s and nodes.

Storage Backends
InfluxDB and Grafana
Google Cloud Monitoring

# 14:40
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/  
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/#before-you-begin  
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/#getting-a-shell-to-a-container  
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/#writing-the-root-page-for-nginx  
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/#running-individual-commands-in-a-container  
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/#opening-a-shell-when-a-pod-has-more-than-one-container  
This is review. All makes sense to me.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#node-problem-detector  
Good lord is there anything this can't do? This is a system for monitoring
the health of nodes that can be deployed into k8s.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#limitations  
Only works for Debian/Ubuntu Nodes presently.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#enabledisable-in-gce-cluster  
Available as an add-on in GCE.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#use-in-other-environment  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#kubectl  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#addon-pod  
To use outside of GCE, just add the DaemonSet.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#overwrite-the-configuration  
Some notes about how the docker image for the node problem detector contains
the configuration but will defer to ConfigMaps if they are present.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#kernel-monitor  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#add-new-nodeconditions  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#detect-new-problems  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#change-log-path  
https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#support-other-log-format  
Makes sense to me.

https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/#caveats  

# 15:10
https://kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/  
https://kubernetes.io/docs/tasks/debug-application-cluster/events-stackdriver/  
https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#before-you-begin  
Skipping.

# 15:15
Break to talk to @mattsurabian about PostgreSQL and @taraalan about
Woodland Kitchen.

# 15:55
https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/  
https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#before-you-begin  
https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#writing-and-reading-a-termination-message  
https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#setting-the-termination-log-file  
All review, except that the container spec supports `terminationMessagePath`
which controls where a container may write it's termination output. The
default is /dev/termination-log.

# 16:05
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-init-containers/  
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-init-containers/#before-you-begin  
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-init-containers/#checking-the-status-of-init-containers  
https://kubernetes.io/docs/tasks/debug-application-cluster/debug-init-containers/#getting-details-about-init-containers  
This is review about how to set up containers that run in-order to prepare
the main container to run. Did it anyway. Worked fine!

# 16:10
https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/  
Makes sense to me. The further I go down this rabbit hole the more I realize
that things like the autopilotpattern are just not relevant. At first I
thought I should try to remain scheduler agnostic, but that makes about as
much sense as being database agnostic... none. I chose a database and use it
because I want the features it has. Why would I hamstring myself by using
the lowest common denomintator of features? I think I *want* to be hitched
to this scheduler.

# 16:15
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#before-you-begin  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#use-kubectl-to-create-a-configmap  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#create-configmaps-from-directories  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#create-configmaps-from-files  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#define-the-key-to-use-when-creating-a-configmap-from-a-file  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#create-configmaps-from-literal-values  
https://kubernetes.io/docs/tasks/configure-pod-container/configmap/#understanding-configmaps  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#before-you-begin  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#define-pod-environment-variables-using-configmap-data  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#define-a-pod-environment-variable-with-data-from-a-single-configmap  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#define-pod-environment-variables-with-data-from-multiple-configmaps  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-pod-environment-variables  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#use-configmap-defined-environment-variables-in-pod-commands  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-volume  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#populate-a-volume-with-data-stored-in-a-configmap  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-specific-path-in-the-volume  
https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#project-keys-to-specific-paths-and-file-permissions  
https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#use-environment-variables-to-define-arguments  
This is review about how to manage ConfigMaps. I read this a week or so ago
but I'm giving it another look. All makes sense to me.

https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#mounted-configmaps-are-updated-automatically  
ConfigMaps which have been projected as a file update automatically based on
the node kubelet sync period + ttl.

https://kubernetes.io/docs/tools/kompose/user-guide/  
Skipping.

https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/  
https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#define-a-command-and-arguments-when-you-create-a-pod  
It's possible to define commands to run when a container is created using
the container spec properties `command` and `args`.

https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#use-environment-variables-to-define-arguments  
You can interpolate environment variables just like the shell.

https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#run-a-command-in-a-shell  
If you want to run multiple commands, pipe things, etc, make the command be
a path to the shell you'd like to use (e.g. /bin/sh or /bin/bash)

https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes  
If you do not specify `command` or `args`, Docker's ENTRYPOINT/CMD is used.
If only `command` is specified, Docker's ENTRYPOINT/CMD is ignored.
If only `args` is specified, Docker's ENTRYPOINT is used & args are passed.
If `command` AND `args` are specified, Docker's ENTRYPOINT/CMD is ignored.

# 16:30
Talking w/ Mike.

# 18:05
Hangin' with Tara, talking with friends.

# 22:00
Back for more.

https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#before-you-begin  
https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/#define-an-environment-variable-for-a-container  
Basic stuff here. You can set environment variables in a container spec.

https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#before-you-begin  
Check.

https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#the-downward-api  
Pod and Container fields can be supplied to a running container via
environment variables.

https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#use-pod-fields-as-values-for-environment-variables  
When specifying an environment variable, use the `valueFrom` key to do
introspection.

That is:
```
env:
- name: MY_NODE_NAME
valueFrom:
fieldRef:
fieldPath: spec.nodeName
```

Cool.

https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#use-container-fields-as-values-for-environment-variables  
Same story for using container values, but the valueFrom is a bit different:
```
env:
- name: MY_CPU_REQUEST
valueFrom:
resourceFieldRef:
containerName: test-container
resource: requests.cpu
```

# 22:15
https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#before-you-begin  
https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api  
Pod and Container fields can be supplied to a running container a "downward"
api.

Based on my read, this is configuration sugar for dynamic ConfigMaps defined
by values plucked from the container or pod spec. Neat.

https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#store-pod-fields  
```
volumeMounts:
- name: podinfo
mountPath: /etc
readOnly: false
volumes:
- name: podinfo
downwardAPI:
items:
- path: "labels"
fieldRef:
fieldPath: metadata.labels
- path: "annotations"
fieldRef:
fieldPath: metadata.annotations
```

...this leads to files "/etc/path" and "/etc/labels" being on disk with the
appropriate values. These files are symlinks to other files in /tmp. When
values change, the symlink is updated.

https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#store-container-fields  
This is the same as the previous example with slightly different pathing.

https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#capabilities-of-the-downward-api  
Labels and annotations are only available via downward api files. Presumably
this is because their values are not strings.

# 22:25
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/  
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#before-you-begin  
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#convert-your-secret-data-to-a-base-64-representation  
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#create-a-secret  
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#create-a-pod-that-has-access-to-the-secret-data-through-a-volume  
https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#create-a-pod-that-has-access-to-the-secret-data-through-environment-variables  
This is review about using Secrets.

# 22:30
https://kubernetes.io/docs/tasks/inject-data-application/podpreset/  
When I originally read about this I was skeptical. I thought each Pod spec
should have an external reference to some shared file if sharing was needed.

I realize now that wouldn't be very dynamic. I'm starting to come around to
the operational simplicity of having the ability to specify specific
properties that selected Pods in the cluster will automatically have.

https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#simple-pod-spec-example  
https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#pod-spec-with-configmap-example  
Looks like this is orchestrated by the admission controller. It leaves an
annotation stating which preset and what version was used. Neat.

https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#replicaset-with-pod-spec-example  
ReplicaSets don't inherit

https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#multiple-podpreset-example  
Multiples works like you'd think. One annotation for each preset applied.

https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#conflict-example  
When there is a conflict across two pod presets it looks like neither is
used. This is visible in the events for the Pod.

https://kubernetes.io/docs/tasks/inject-data-application/podpreset/#deleting-a-pod-preset  
I wonder if Pods automatically update when a preset is changed.
Testing...

Seems PodPresets aren't enabled in minikube yet.

# 22:40
Stopping to help Tara install and use ffmpeg.
