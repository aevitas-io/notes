# 13:40
Digging in again. Going to start with re-reading my notes from the 8th.

https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-iptables  
Happens at the kernel/netfilter level by configuring iptables. Same net
effect, just faster, presumably.

Pretty cool. Did a quick google to see more about the implementation.
https://github.com/kubernetes/kubernetes/issues/3760  
This is a very lengthy issue. Moving on after a healthy skim.

https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-ipvsalpha  
IPVS can be faster than iptables on clusters with tons of services because
it uses hash table look ups. Still netfilter under the hood. Also, more
robust load balancing features are available and is arguably easier to
understand for debugging.

https://kubernetes.io/docs/concepts/services-networking/service/#multi-port-services  
When using multiple ports you have to name them so the underlying Endpoints
that get created know which to use.

https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address  
It's possible to assign your own clusterIP if you need to replace a legacy
system that might expect a specific IP that is difficult to reconfigure.

https://kubernetes.io/docs/concepts/services-networking/service/#why-not-use-round-robin-dns  
Some downsides to round-robin DNS are enumerated. Makes sense to me.

https://kubernetes.io/docs/concepts/services-networking/service/#discovering-services  
Two ways. Environment variables and DNS.

https://kubernetes.io/docs/concepts/services-networking/service/#environment-variables  
Only works on services that exist at the time of pod creation.

https://kubernetes.io/docs/concepts/services-networking/service/#dns  
DNS server watches Services resources and creates matching DNS entries.
Makes sense to me.

# 14:30
Going to experiment a bit using minikube for headless services...

https://kubernetes.io/docs/concepts/services-networking/service/#headless-services  
Skip load balancing and having a single IP for your Service. Done by
specifying `None` for the clusterIP. No help from kube-proxy on these
types of services. DNS configuration is controlled by Service selectors...

https://kubernetes.io/docs/concepts/services-networking/service/#with-selectors  
If you define selectors k8s make an endpoint for each Pod. DNS entries
created that give back all the IPs of the Pods.

https://kubernetes.io/docs/concepts/services-networking/service/#without-selectors  
If you do not define selectors, no Endpoints records are created and thus
no DNS entries except for ExternalName services and
"A records for any Endpoints that share a name with the
service, for all other types."
^ Not sure what this means.

I created Services with varying configs and observed how Endpoints are or
are not created, and how DNS resolution is affected. Neat stuff.

# 15:00
https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types  
Various types allowed for services.
ClusterIP
Communication only within the cluster.
NodePort
Automatically creates a ClusterIP Service. Service is available by node
IP and port.
LoadBalancer
Creates NodePort and ClusterIP, also manages some external load balancer.
ExternalName
No proxying. Allows creating a CNAME entry to any machine at the cluster
level using whatever internal name you want.

https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport  
K8s master chooses a port at random and sets up proxying on both the
cluster and Node level for that port, into the service desired. Load
balancing to the world is up to you.

https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer  
For cloud providers who support load balancers, this automatically handles
configuration. I'm curious how expensive this would get on AWS...

https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer  
Split horizon DNS is supported through simple annotations.

https://kubernetes.io/docs/concepts/services-networking/service/#ssl-support-on-aws  
SSL is supported trivially on AWS as long as you manage certs yourself with
IAM.

https://kubernetes.io/docs/concepts/services-networking/service/#proxy-protocol-support-on-aws  
PROXY support is possible too.

https://kubernetes.io/docs/concepts/services-networking/service/#external-ips  
Allow specifying which external IPs are valid for communication with the
cluster. It's up to the network administrator to deal with the rest.

https://kubernetes.io/docs/concepts/services-networking/service/#shortcomings  
Userspace proxy is fine for small/medium clusters. It obscures the source
IP, making certain types of firewalls impossible. Iptables doesn't have this
issue.

The type field is meant to be nested (clusterIP->NodePort->LoadBalancer)
...but not all cloud providers need it to be. e.g. GCE doesn't, AWS does.

https://kubernetes.io/docs/concepts/services-networking/service/#future-work  
Looking to add more complex load balancing options etc.

https://kubernetes.io/docs/concepts/services-networking/service/#the-gory-details-of-virtual-ips  
Yes please, tell me everything.

https://kubernetes.io/docs/concepts/services-networking/service/#avoiding-collisions  
Users should not be exposed to things failing they didn't cause directly.
Ports should be selected by the system, not users. Each Service has its
own IP address so ports don't overlap. As each IP is created it is persisted
in etcd. Until that happens, a service cannot be created.

https://kubernetes.io/docs/concepts/services-networking/service/#ips-and-vips  
Pods have actual IPs you can communicate with.
Service IPs are virtual and defined by iptables rules. Environment variables
and DNS are configured based on the virtual IP of the service.

https://kubernetes.io/docs/concepts/services-networking/service/#userspace  
Review of previous section.

https://kubernetes.io/docs/concepts/services-networking/service/#iptables  
When a service is created every single kube-proxy instance in the cluster
sees it and installs iptables rules for the Node in which it resides,
pointing at the virtual ip, which in turn point to per-Endpoint rules that
NAT the connection back to a desired pod.

In this mode packets are not copied to userspace, they pass through the
kernel. If kube-proxy dies, routing still works.

https://kubernetes.io/docs/concepts/services-networking/service/#api-object  
Skipping.

# 15:30
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#introduction  
A DNS service is installed automatically by Kubernetes under the kube-system
namespace. All containers are instructed to use it when resolving DNS.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#what-things-get-dns-names  
Every Service gets a DNS entry. Pods can do DNS lookup in their own
namespace without defining it.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#a-records  
Services get an A record:
<service-name>.<namespace>.svc.cluster.local.
Normally this resolves to a clusterIP.
"Headless" services returns all Pod ips and consumers do whatever they want.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#srv-records  
Only created for named ports.
_<port-name>._<protocol>.<service-name>.<namespace>.svc.cluster.local

...why the underscores? Some googling shows it might have something to do
with etcd?

# 16:00
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pods  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#a-records-1  
When enabled a Pods gets an A record:
<ip-dash-separated>.<namespace>.pod.cluster.local

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#a-records-and-hostname-based-on-pods-hostname-and-subdomain-fields  
...a sea of notations about what existed in old versions of Kubernetes.
Skipping for now.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#how-do-i-test-if-it-is-working  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#create-a-simple-pod-to-use-as-a-test-environment  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#wait-for-this-pod-to-go-into-the-running-state  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#validate-that-dns-is-working  
Makes sense to me.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#troubleshooting-tips  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#check-the-local-dns-configuration-first  
Check /etc/resolv.conf in the container for search paths.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#dns-policy  
When using hostNetwork, you don't get cluster-level DNS unless you opt in
with `dnsPolicy`.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#is-dns-service-up  
Ensure DNS service is running:
`kubectl get svc --namespace=kube-system`

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#are-dns-endpoints-exposed  
Ensure endpoints are present...
`kubectl get ep --namespace=kube-system`

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#quick-diagnosis  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#check-if-the-dns-pod-is-running  
https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#check-for-errors-in-the-dns-pod  
If you can't resolve kubernetes.default, check for running kube-dns pods:
`kubectl get pods --namespace=kube-system`
If you have pods... check logs.

First, get a DNS pod name:
```
dnspod=$(kubectl get pods --namespace=kube-system -o name -l k8s-app=kube-dns)
```

...then check logs:
```
kubectl logs $(dnspod) --namespace=kube-system -c kubedns
kubectl logs $(dnspod) --namespace=kube-system -c dnsmasq
kubectl logs $(dnspod) --namespace=kube-system -c sidecar
```

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#kubernetes-federation-multiple-zone-support  
K8s 1.3 supports DNS resolution across clusters. Neaaat.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#how-it-works  
A DNS pod has three containers
Kubedns
Watches for changes in Services / Endpoints and retains in-memory mapping.
Dnsmasq
Caching for performance
Health Checker
Just what ya'd think.

DNS pod is exposed with a static IP: 10.0.0.10.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#inheriting-dns-from-the-node  
By default Pods get cluster DNS prepended. If you want something different,
use --resolve-conf when starting up kubelets.

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#known-issues  
The node-level resolve.conf is not adjusted by kubelet. Should probably be
resolved but it is specific to each linux distro.

# 14:25
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#the-kubernetes-model-for-connecting-containers  
Docker uses host-private networking. Containers can only reach containers on
the same machine. This requires careful coordination. Kubernetes solves this
by allowing all Pods to communicate with other Pods regardless of the host
they are on. All Pods get their own IP and each container inside it can
communicate directly over localhost.

https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#exposing-pods-to-the-cluster  
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#creating-a-service  
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#accessing-the-service  
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#environment-variables  
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#dns
All review. Makes sense.

https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#securing-the-service  
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#exposing-the-service  
Makes sense. Shows how to take a nginx service and spin it up with https
certs mounted to disk from a secret.

# 14:35
https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress  
This resource controls external traffic reaching internal nodes.

https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-controllers  
These docs are outdated, I believe, but they state the k8s project supports
a nginx and gce controller.

Lowering my confidence level in everything I read here--only accepting high
level concepts as reality.

https://kubernetes.io/docs/concepts/services-networking/ingress/#prerequisites  
This is way out of date.

https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resource  
Makes sense to me. This is the high level config that should ideally work
across all load balancers.

https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-controllers  
https://kubernetes.io/docs/concepts/services-networking/ingress/#before-you-begin  
I think this is out of date and is actually related to the cloud controller
manager. Skipping.

https://kubernetes.io/docs/concepts/services-networking/ingress/#types-of-ingress  
https://kubernetes.io/docs/concepts/services-networking/ingress/#single-service-ingress  
Makes sense. This is for port forwarding to a Service/clusterIP.

https://kubernetes.io/docs/concepts/services-networking/ingress/#simple-fanout  
Makes sense. URL mapping to services.

https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting  
Makes sense. Single IP for multiple services routed by hostname.

https://kubernetes.io/docs/concepts/services-networking/ingress/#tls  
Dope. You can configure a convention-based secret to handle TLS termination.
I wonder if this is still true. This defer users to the ingress controller
of choice for confirmation.

https://kubernetes.io/docs/concepts/services-networking/ingress/#loadbalancing  
At the time these docs were written, load balancing was primarily happening
at the Service level. Some of that functionality may be moved up the stack
as well.

https://kubernetes.io/docs/concepts/services-networking/ingress/#failing-across-availability-zones  
Deferred to cloud provider's ingress controller.

# 14:45
https://kubernetes.io/docs/concepts/services-networking/network-policies/  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#prerequisites  
NetworkPolicy resource. Requires a network policy controller.

https://kubernetes.io/docs/concepts/services-networking/network-policies/#isolated-and-non-isolated-pods  
By default all Pods accept traffic from anywhere.

https://kubernetes.io/docs/concepts/services-networking/network-policies/#the-networkpolicy-resource  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-policies  
NetworkPolicies are assigned at the namespace level. If none is present,
all traffic is allowed.

https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-ingress-traffic  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-allow-all-ingress-traffic  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-egress-traffic  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-allow-all-egress-traffic  
https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-ingress-and-all-egress-traffic  
All makes sense to me.

# 14:50
https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/  
Kubelet manages pod-level /etc/hosts

https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#default-hosts-file-content  
Makes sense to me.

https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#adding-additional-entries-with-hostaliases  
https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#limitations  
The pod specification supports a `hostAlias` configuration for adding
entries to /etc/hosts

https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/#why-does-kubelet-manage-the-hosts-file  

K8s manages the /etc/hosts file to prevent docker from messing with it.
What are you *doing* docker? Blegh.
https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/  

# 14:50
https://kubernetes.io/docs/concepts/storage/volumes/  
Already read this.

Signing out to prepare for dinner with neighbors.
